{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMILE Data - VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNv8w9UwzamBeRLJ1XQuIcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nwanna-Joseph/Variational_Autoencoder/blob/main/SMILE_Data_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A demonstration of creating Variational Autoencoders using the SMILE dataset**"
      ],
      "metadata": {
        "id": "pl3ddgPCdcE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Generating new SMILE data that wasn't used for training"
      ],
      "metadata": {
        "id": "0Wr00-Q4ef7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports!"
      ],
      "metadata": {
        "id": "haNkcgqnWGgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# from utils import softmax \n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "DXZlIzd6WIFA"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utils"
      ],
      "metadata": {
        "id": "sqKSqGfRVWCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SMILEText:\n",
        "  def __init__(self):\n",
        "    with open('/content/smiles.txt','r') as f:\n",
        "      self.text = f.read()\n",
        "      self.unique_chars = set(self.text)\n",
        "      self.from_array= self.text.split('\\n')\n",
        "\n",
        "smile_text = SMILEText()"
      ],
      "metadata": {
        "id": "HFh8YKMOv0Ug"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SMILESEncoder:\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "        # Allowed tokens (adapted from default dictionary)\n",
        "        self._tokens = np.sort([k for k in smile_text.unique_chars])\n",
        "        self.image_template = np.zeros((200,len(self._tokens)+1)) #+1 for unknown. 100 * number of unique chars\n",
        "\n",
        "        self.c2i = {}\n",
        "        self.i2c = {}\n",
        "\n",
        "        for i,c in enumerate(self._tokens):\n",
        "          self.c2i[c] = i\n",
        "          self.i2c[i] = c\n",
        "\n",
        "    \n",
        "    def encode( self, data ):\n",
        "\n",
        "      assert len(data)<100\n",
        "\n",
        "      char_image_template = self.image_template[:,:]\n",
        "\n",
        "      for i,c in enumerate(data):\n",
        "        char_image_template[i][self.c2i[c]] = 1\n",
        "\n",
        "      return np.array(char_image_template)\n",
        "\n",
        "\n",
        "\n",
        "    def decode(self, one_hot):\n",
        "      text = \"\"\n",
        "      for row in one_hot:\n",
        "        for i,elem in enumerate(row):\n",
        "          if(elem == 1 and self.i2c.get(i)):\n",
        "            text += self.i2c.get(i)\n",
        "      \n",
        "      return text"
      ],
      "metadata": {
        "id": "FiRc1bbcVbo9"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    \"\"\"Softmax function \"\"\"\n",
        "    # raise NotImplementedError\n",
        "    return torch.nn.functional.softmax(z,dim = 0)\n",
        "smiles_encoder = SMILESEncoder()\n",
        "def idx_to_sequence(idx):\n",
        "    return smiles_encoder.decode(idx)\n",
        "\n",
        "def sequence_to_idx(sequence):\n",
        "    return smiles_encoder.encode(sequence)"
      ],
      "metadata": {
        "id": "2AhNhtnXVm7i"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unit tests\n",
        "test_sequence = smile_text.from_array[10]\n",
        "print(\"SMILE data : \",test_sequence)\n",
        "to_idx = sequence_to_idx(test_sequence)\n",
        "print(f\"One hot encoding for {to_idx.shape} , {test_sequence} : \\n\",to_idx)\n",
        "to_char = idx_to_sequence(to_idx)\n",
        "print(f\"To SMILE data : \", to_char )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr1t0BlJGKuK",
        "outputId": "adcf0206-3ca2-4409-a460-530e64b8c62e"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMILE data :  c1ccc(cc1)[C@@H](C(=O)[O-])O\n",
            "One hot encoding for (200, 35) , c1ccc(cc1)[C@@H](C(=O)[O-])O : \n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "To SMILE data :  c1ccc(cc1)[C@@H](C(=O)[O-])O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def temperature_sampling(temperature):\n",
        "\n",
        "  \"\"\"\n",
        "  Temperature sampling wrapper function\n",
        "  This wrapper function will allow us use the temperature sampling strategy to decode our predicted sequences\n",
        "  \"\"\"\n",
        "  \n",
        "  def decode(preds):\n",
        "\n",
        "    \"\"\" \n",
        "    Decoder using temperature \n",
        "    \"\"\"\n",
        "\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    reweighted_preds = softmax(torch.tensor(preds))\n",
        "    probs = np.random.multinomial(3, reweighted_preds, 3)\n",
        "\n",
        "    return np.argmax(probs)\n",
        "\n",
        "  return decode"
      ],
      "metadata": {
        "id": "09dHW67rVXdG"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Temperature Sampling Unit test\n",
        "predictions = torch.tensor([0.0021, 0.0158, 0.1171, 0.8650])\n",
        "predictions_b = torch.tensor([0.0021, 0.8650, 0.0158, 0.1171])\n",
        "temp_sample_a = temperature_sampling(1)(predictions)\n",
        "temp_sample_b = temperature_sampling(0.3)(predictions_b) #returns the index of the highest prediction\n",
        "print(temp_sample_a)\n",
        "print(temp_sample_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP5tdZ3avBME",
        "outputId": "86a02583-90a8-4bb6-e1f8-ad935e08b115"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Did not use this\n",
        "class View(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(View, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(*self.shape)\n",
        "\n",
        "#Did not use this\n",
        "class ConvVAE(nn.Module):\n",
        "    '''Simple VAE network, based on the example VAE found in \n",
        "    the pytorch examples.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, image_w=200, image_h=200, latent_size=30):\n",
        "        super(ConvVAE, self).__init__()\n",
        "\n",
        "        self._image_w = image_w\n",
        "        self._image_h = image_h\n",
        "        self._latent_size = latent_size\n",
        "\n",
        "        # Encoder layer into latent space.\n",
        "        self._encoder = nn.Sequential(nn.Conv2d(1, 16, 20, stride=20),\n",
        "                                      nn.Sigmoid(), View([-1, 100]))\n",
        "\n",
        "        # Latent space to prob space\n",
        "        self._mean = nn.Sequential(nn.Linear(100, self._latent_size),\n",
        "                                   nn.Sigmoid())\n",
        "\n",
        "        self._std = nn.Sequential(nn.Linear(100, self._latent_size),\n",
        "                                  nn.Sigmoid())\n",
        "\n",
        "        # Latent space to decoded space.\n",
        "        self._decoder = nn.Sequential(\n",
        "            nn.Linear(self._latent_size, 400), nn.ReLU(),\n",
        "            nn.Linear(400, 1 * self._image_w * self._image_h), nn.Sigmoid())\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = self._encoder(x)\n",
        "        return self._mean(h1), self._std(h1)\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mean + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self._decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        return self.decode(z), mean, logvar, z"
      ],
      "metadata": {
        "id": "L8ANJs32v-_k"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Did not use this\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Encoder,self).__init__()\n",
        "        self.input_dimension = 1\n",
        "        self.latent_dim = 20\n",
        "        self.size_of_batch = 32\n",
        "        # Define all layers here\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Sequential(\n",
        "                    nn.Conv2d(self.input_dimension, 16,\n",
        "                              kernel_size= 3, stride= 2, padding  = 1),\n",
        "                    nn.BatchNorm2d(16),\n",
        "                    nn.LeakyReLU()),\n",
        "            nn.Sequential(\n",
        "                    nn.Conv2d(16, 32,\n",
        "                              kernel_size= 2, stride= 2, padding  = 1),\n",
        "                    nn.BatchNorm2d(32),\n",
        "                    nn.LeakyReLU()),\n",
        "        )\n",
        "    \n",
        "    def forward(self, input_x):\n",
        "        \"\"\"\n",
        "        Define the sequence from input to output here\n",
        "        \"\"\"\n",
        "        jump_1 = self.layer1(input_x)\n",
        "        flatten = nn.Flatten()(jump_1)\n",
        "        features_len = flatten.shape[1]\n",
        "        mu = nn.Linear(features_len, self.latent_dim)(flatten) # implement mu here\n",
        "        sigma = nn.Linear(features_len, self.latent_dim)(flatten) # implememt sigma here\n",
        "        return mu, sigma\n",
        "\n",
        "#Did not use this\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Decoder,self).__init__()\n",
        "        self.latent_dim = 20\n",
        "\n",
        "        # Initialize all layers here\n",
        "\n",
        "    def forward(self, input):\n",
        "        # flatten = nn.Flatten()(input)\n",
        "        latent = nn.Linear(38,20)(input.permute(1,0))\n",
        "        #Implement the decoder forward pass here\n",
        "        output = latent\n",
        "        return output\n",
        "#Did not use this\n",
        "class Reparameterization(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "    def forward(self, mu, sigma):\n",
        "        output = ...\n",
        "        return output\n",
        "\n",
        "#Did not use this\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    # def reparameterize(self, mu, logvar):\n",
        "    #     std = logvar.mul(0.5).exp_()\n",
        "    #     esp = to_var(torch.randn(*mu.size()))\n",
        "    #     z = mu + std * esp\n",
        "    #     return z\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder()\n",
        "        # self.encoder = nn.Sequential(\n",
        "        #     nn.Linear(image_size, h_dim),\n",
        "        #     nn.LeakyReLU(0.2),\n",
        "        #     nn.Linear(h_dim, z_dim*2)\n",
        "        # )\n",
        "        # # self.decoder = ...\n",
        "        # self.decoder = nn.Sequential(\n",
        "        #     nn.Linear(z_dim, h_dim),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(h_dim, image_size),\n",
        "        #     nn.Sigmoid()\n",
        "        # )\n",
        "        # self.reparameterization =...\n",
        "\n",
        "    def forward(self, input):\n",
        "      return encoder(input)\n",
        "      pass\n",
        "        # output = ...\n",
        "        # return output \n",
        "        # h = self.encoder(x)\n",
        "        # mu, logvar = torch.chunk(h, 2, dim=1)\n",
        "        # z = self.reparameterize(mu, logvar)\n",
        "        # return self.decoder(z), mu, logvar"
      ],
      "metadata": {
        "id": "Acg2kkP3VjgJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unit tests\n",
        "device = \"cpu\"\n",
        "test_tensor = torch.tensor([a for a in sequence_to_idx( smile_text.from_array[0] ) ], dtype= torch.float32) .reshape(38,1,1,34)\n",
        "test_tensor.to(device)\n",
        "encoder = Encoder()\n",
        "encoder.to(device)\n",
        "encoded_data = encoder(test_tensor)"
      ],
      "metadata": {
        "id": "ZG26lEGwbOAJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, image_size=35 , h_dim=400, z_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, h_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(h_dim, z_dim*2)\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, h_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(h_dim, image_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        esp = to_var(torch.randn(*mu.size()))\n",
        "        z = mu + std * esp\n",
        "        return z\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decoder(z), mu, logvar"
      ],
      "metadata": {
        "id": "W2w9IT4T9z6U"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmileDataset(torch.utils.data.Dataset):\n",
        "  #Adapter pattern (Software design pattern)\n",
        "  def __init__(self, file_path):\n",
        "    with open(\"/content/smiles.txt\",'r') as f:\n",
        "      text = f.read()\n",
        "\n",
        "    #get unique characters in the data\n",
        "    unique_chars = set(text) \n",
        "\n",
        "    #create a map of SMILE character to index\n",
        "    hashmap_char_index = {}\n",
        "    #create a map of SMILE index to character\n",
        "    hashmap_index_char = {}\n",
        "\n",
        "    for idx,ch in enumerate(unique_chars):\n",
        "      hashmap_char_index[ch] = idx\n",
        "      hashmap_index_char[idx] = ch\n",
        "    \n",
        "    #text is a concatenation of all the chemical structure. split them via the next line aka \\n\n",
        "\n",
        "    self.data = text.split('\\n')\n",
        "    #self.data[0] is now C[C@@]1(C(=O)C=C(O1)C(=O)[O-])c2ccccc2\n",
        "\n",
        "    pass\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    return self.data[idx]"
      ],
      "metadata": {
        "id": "syQrTn2ZjuGf"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(SmileDataset(\"/content/smiles.txt\"), batch_size = 32)\n",
        "model = VAE()\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr = 0.0001)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "4HiV_MlgQn6v"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(recon_x, x, mu, logvar):\n",
        "    BCE = torch.nn.functional.binary_cross_entropy(recon_x, x, size_average=False)\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 -  logvar.exp())\n",
        "    return BCE + KLD, BCE, KLD"
      ],
      "metadata": {
        "id": "XTEWPLba-pgc"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(x):\n",
        "    return to_var(x.view(x.size(0), -1))\n",
        "    \n",
        "def save_image(x, path='real_image.png'):\n",
        "    torchvision.utils.save_image(x, path)\n",
        "\n",
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)"
      ],
      "metadata": {
        "id": "dzfHYzzV_Jv9"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = iter(trainloader).next()[0]\n",
        "test = flatten(torch.tensor( sequence_to_idx(test), dtype= torch.float32 ))\n",
        "\n",
        "mu_learnt = None\n",
        "std_learnt = None\n",
        "loss_array = []\n",
        "bce_loss_array = []\n",
        "kld_loss_array = []\n",
        "for epoch in range(2):\n",
        "    for idx, image in enumerate(trainloader):\n",
        "        # images = [print(sequence_to_idx( a ).shape) for a in image ]\n",
        "        images = flatten(torch.tensor([sequence_to_idx( a ) for a in image ], dtype= torch.float32).reshape(-1,1,1,35))\n",
        "\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        mu_learnt = mu\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        std_learnt = std\n",
        "        \n",
        "        loss, bce_loss, kld_loss = loss_fn(recon_images, images, mu, logvar)\n",
        "        loss_array.append(loss)\n",
        "        bce_loss_array.append(bce_loss)\n",
        "        kld_loss_array.append(kld_loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if idx%100 == 0:\n",
        "            print(\"Epoch[{}/{}] Loss: {:.3f}\".format(epoch+1, 2, loss.item()/32))\n",
        "    \n",
        "            # recon_x, _, _ = model(test)\n",
        "            # save_image(recon_x.view(1, 1, 200, 35).data.cpu(), f'/content/reconstructed/recon_image_{epoch}_{idx}.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "_13A5i8J-3xO",
        "outputId": "dbe6da24-1eff-483f-d6a8-b8348aa450c7"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 35])\n",
            "Epoch[1/2] Loss: 4849.317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1/2] Loss: 855.314\n",
            "Epoch[1/2] Loss: 809.248\n",
            "Epoch[1/2] Loss: 700.765\n",
            "Epoch[1/2] Loss: 659.113\n",
            "Epoch[1/2] Loss: 635.517\n",
            "Epoch[1/2] Loss: 630.030\n",
            "Epoch[1/2] Loss: 620.514\n",
            "Epoch[1/2] Loss: 612.607\n",
            "Epoch[1/2] Loss: 618.477\n",
            "Epoch[1/2] Loss: 645.797\n",
            "Epoch[1/2] Loss: 584.799\n",
            "Epoch[1/2] Loss: 580.062\n",
            "Epoch[1/2] Loss: 581.203\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-307-20bbb91314f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from decoder import temperature_sampling\n",
        "# from utils import idx_to_sequence\n",
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('epochs', type=int, help='number of full forward passes through data')\n",
        "\n",
        "# parser.add_argument('') # You may add more arguments here! .....\n",
        "\n",
        "# args = parser.parse_args()\n",
        "\n",
        "\n",
        "#mini overrides\n",
        "epochs = 1\n",
        "\n",
        "def train(trainloader, \n",
        "          model,\n",
        "          epochs,\n",
        "          optimizer,\n",
        "          criterion)->None:\n",
        "    model.train() \n",
        "    for epoch in range(epochs):\n",
        "        for data in trainloader:\n",
        "            test_tensor = torch.tensor([a for a in sequence_to_idx( data ) ], dtype= torch.float32) .reshape(38,1,1,34)\n",
        "            print(test_tensor.shape)\n",
        "            prediction = model(data)\n",
        "            # loss = criterion(prediction, label)\n",
        "            # optimizer.zero_grad()\n",
        "            # loss.backward()\n",
        "            # optimizer.step()\n",
        "\n",
        "def generate(model, mu, std):\n",
        "    model.eval()\n",
        "    z = np.random.normal(mu.detach().numpy(),std.detach().numpy()) #from s = np.random.normal(mu, sigma, 1000), generating some random texts from the distribution\n",
        "    out_probs = model.decoder(torch.tensor(z,dtype=torch.float32)) #z is expected to be numpy. Here, it's being converted to \"Tensors\" and fed to the decoding model\n",
        "    \n",
        "    output = \"\"\n",
        "    for row in out_probs.detach().numpy():\n",
        "      dx = temperature_sampling(1)(row)\n",
        "      ch = smiles_encoder.i2c.get(dx)\n",
        "      if(ch):\n",
        "        output += ch\n",
        "\n",
        "    # print(output)\n",
        "\n",
        "    generation = output#idx_to_sequence([[0,] for  temperature_sampling(1)(out_probs.detach().numpy())]) #output probs is a tensor thet's converted to numpy for use in numpy. It's being passed to temperature_sampling which needs to call .decode()\n",
        "    return generation\n"
      ],
      "metadata": {
        "id": "veZCtbAVVgAj"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate( model, mu_learnt, std_learnt )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "0PkC5EZaYi5B",
        "outputId": "2266b085-7e57-4741-a237-de1537c326fc"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C#C#)(/F-(#)#(S/[H+15[)(2#+)-/(F##C-=)r#()@+3BC#3N4-+#)(CC))C3)3)O)OC33)3O33CC33OOC)3333O)OCC3C3)3)O3)3O33)3)33)CC333C3OC3)OC)333O)33C3C33333O))3333O3))3CCO333)C1=@(PF4/+[4#-(#1##/#1(I))5#1/++/+34+c+3#3#1))(16))l#N=+])]3]]O)))C)OO3))3)3))3O)33OC))3O33)))3)333)33F)3))33))O333CCO33O33C333)3)3O33CO33)O)3))33)33O33CO33C33CC@=H(34@-CH#)@\\\\)#2@F--)4H(+(5Ho(-5-(1-/C#5]@/(21+)(#)#-COO=]C)C)C)333O))C3OC3)O)))33)C)))33))3333)O33333C3C33)O3333C33)3O)33)O3)OO3333O3C33)O3O3))33333O333)33C333)[C/+1n/4-42P/(F#]l@5B-[5-()\\\\6(s)6/(\\\\-N4O)#2#)s45[Ol((=)4=])3l)C33)O3OCOC)3COO))3OO33333)333333)C))3)O)O)3O)C333)3O)C33)C33)3)3)33)C)3O)CO33C)3)3)333OC)333)C3O)O)3)OO3)CcO+H+C()#(-H]-(-r1P(B4#@/I/B])@42@(3@-#)B-+/21H]4##+#5OOO--O)[)C3)O3)O)3C3333C3333))3)O)O3)33C3)333))3C3O)3OC)O)3333)))))33))3C3)O333)33)333)3)COO3)33333C3333C33CCOC(-+141)//OFC+)rB()+2/(#/)H)HB)(=5/5(#n(/C/+4#S=C3445)c=34C--)O)O)3C33)3O333)3O3)333333O33CO)33333)O)OC33)C3))33333C333C3C3)O33)O))33)C3)333)33333C)33)C333C3O33)3O))CC+=-##4B))()-F=N=//o-C1B#N//)/-3+#-2)3-/)(1N(2(4#+443C-F4CO3))C3)3)333CCC3)O33)3))33C33CCO))3))C33)3)))3C33)33)))3)3OO333C))C3))CCO))3CO)3)3C3))333c3O33)O3)C)O3)3)O3Cc)-33B(Br4((1=B(11#5)C1-\\\\/H#+)14#5#2522)c(#4C122(#r)-((O[(-C)3)C3)C333O33OC3))3C33C3)C333CC)OO)C3O3)O3C)CO3)OO33OC)3C3))33C)3CC3C3))333333))3)O)33OO333O))3333)[S(c-)-==+#-)(2-O2)43#(@#6=3)3(4(+/()C=1)O#S#[)l52351=()()[=OC4(=F3O))3O))33)C33)33)))3)3CO)CO))33)O3333O3O33333c))33O33)3)3)3OC))33CO)333)))3)3)3)3O))3))C3)CO)33O3)33O)O))33cOo2=)H##3--)F))B//#5C1=B+/(3##n-B+3#-(+2)2=1-11/4)(=O#4+O-4C-3O)333))O3333O3)O33C))CO)O-33COO)33)333O)3)C3O3333O)3O333OO)33)))3333)3OC3C3333)CO)3333C))))3))3333O3C1(()NS[5+SF41@O3+4+42)@)#IS(c/)(+3+)1-I=#N)-C312)](COCO-)]O3)FOOO3COC)3O3O33))C3OO3C)O3333)OO)3O3))C)C3)))C3C))3CO33O3O333OO)33)O))3CC33)3)333OCOO)OO)O)3)CC+N#(#C+P)+1(5==F(N@@24/+(-#-1@#H3315--2+r3#F-H-O1)N#-3N(3[O)+)C3)O)333333O33O)O(3O3C)33OO33))))3O3)OC)OC)33O))3F33OO3)O33C)333O333O)C)3333C3O333C33)333333333O3O))3)O))OCn/+=sl(N-@H==3I((+(3(4[+4)5/O5][1=C#)(C-)(+42N3)#ON355OC-CCO3)O)C)33)3O3C)3333333O3333333OO3)O333OOO3)O33O))O333O3OO3))3)))C-OO33)))O33333CO333O3))))33OC)3O33)3CCC##+(=)+n-1B1)P+21=4#@H4//1--()56+(/#(C)(@C4(N3/-=23#C+)[-4]O)))OO)33)O3)3O33)333O))C)3333O333O)))3)3)3)O3))3CC3)3CCOOC3))3))CC33333)333C)OC)333333))33O3)3O33C)[((#/-1)=+(+H@()-/H(/#-5#1-)-#C4+)-4#=H(O)=3C2-22c1-]F))=OC[C33)OOCO3)C3)))33)3F3OOO33)CO3))33C3)C3C3)3OC3)OC3C3O3)C333O33333C33))O3O)3))3)O)))33)3)OO))O333)3OO3)3CC/@3##))-=C-C)B#(3#C11B352+2]6F#2+54@5-]\\\\S1((3+)4+)(-+5)4(#]-))3))C3O3))))3C3)3O3)3)3CO)3O333CC3333333C3))3)3O3O3CO333O)33)3333)3O3)C3O33C3OC3)333)3C33O33))O3OO33OC()1(#c4/##O#+BI-(5H#61+C51-@+#2#]3(6-@(#2oB31@3]51)=)(F()OC3)3OCC3333)3O3))))C3CO)3)333O3)33C3CCC)33333F3C3OC)))33C33333)33O333CO33)3C333)33333C3))3)3#[N#C-(3)2+@##(+)I+=\\\\C2+2)3F((6H)B)+)-NS=)-O]O(3C+l])+#(-O+])C3OC)CC3)33)33C)333O333CO)3))3)))O3))33O))33))O3333C33OCC3)C3)3333)O33O)O3O3)OC)OC)CO3)))C)OO3)3)333))3c+)-sN3I-n+1-#-(=B)F(#(#+B@(42C((34/@HN-@#N2(-(-4()[O=CC3)OCC3)O)O333O33O333)3)33)C33OO)33)3))3O333O3333)O)OCO333333C3))33OC3CO333C))))))3)33333)3)33))3C33))3C)3O)))3/2#)/+#P42-45)+C/#54#+21+1513)5#+cB1##5@H)C-15=3)H-O3)3))3)C)33333)C3COC333))OO3OCO3)C)33OOC))33C33OCOO33)33O)O)3)3))C33O))-3OC3OO))O)3O3C33333O)O)O3C[/[+)@@]2H=/)1/@31I4@CO3NBB)o3Bl#55/O-=F(123+@+=H11)5F=#(#C+OCC3OO)OO3)3))3C)333O3)O)33)CO3)OC)O33O33))O3O33C)3))OO))3)3)333333333OO)3C33333)3OOC3O)3C)O)3)3C3O)33)3Cc#@[)(1)2/5#4/))O=45#C-(C)--33(B#5@2)-+=CHF-N(H3(#C((5=F))[3)OCC33C333)O3)O333)3O33333COCO)33C33)3C)C)))O3OO3)O3)3)3)3)3)333CO3333CO3O)CCC33C3C)C)333333C33OO33)3O33333)33cN#ON#C-H#/#222IP3+C-N(22+@#(5#SlsH)(+FH=44O/#(-=1555((1N#C(5(O]O33)C3)))3333333OO33OO3))O3C)3O3CC33333))3C)3)O33)O3OC)OC)33)C3)))O)33))))OO33CC)33)))))333333O3)O)#/1[1/F/(22-#3++#)#S25@/@NF-=)#53)H)/)1([=BSc23[C44)3N)#)#-C]C3)OCC)3)333)3O3)3)C)3O33OO)3333)333)O3)OC33333))CCC3C)3)3O)333)333)O))3OC33)))3)33C33))3))33)33C)O33333O3)C[=O+#/#]+@C)B3+-#1/+)@1@)365BO3(2)15l5F+1C1(F5))+)F)(=4)C3)C)3))))33)CO)3)3)O3O)33O33)33OOOO3)O3O3)33)33333O)3)O)33333OO3)3)CC)33O3C)3C)O3O3333OO)333)33))H333Cn+/+)H-F#(+#s(32=rII-+/())533##@)#@/)5/-)/(2-=4)44))F3)#N]O3)OC333)C)O)33CCC)C33O))C33)3O3O)333)3333)333)O)3C)333OO3)3)333CO3)3CO)3)3O33))333)O33)O))33333)3O)3))O3O3C@2+O@)-2#)/#-@4-3(#)/#/6@BN2@F(2C\\\\@#@/F#(/)=)1O4213-=)#3=][C=])CC3333333O))333333)O3)O33C3)33)3)O))CC))CO3CC33333333C3)3O3C333O3)333)))3OC))OO33OOO)3333)))))3OO)O#S2(2@(22(-4F##2r3/5S(#c+2S]((S@2/n)CCN(3#((#+O@(4#13C()453))O]3OC))OCO))3)33)3))C333)3)OOO)C3O3)O3))))C)33C3))33)3C3)3)33333)C3)333)CO))3O3)3OO33333O33)O3)S(/-H222H3()(N#5#(##232+B3#-111#/++42+H3=#()B113(-())+F)C))))C3333C)33)33O3O)3H3))3)O))3)C))3))333O3)3333C))3O333333)33COO3)3333C333O33O3C)3)3#3C)OO3OO3OC33)3C[O#c##+n#)#141C@@O(B/)4+)@+C(-)@42+=2/+)#+)--+5=(4)5#)OOC))C))3)333)33O)O3)333O333)33O))O)333)C)3O333)3)C)))3)3))33333O)3))333C33C3)O)COOC33C3)33))3)33CO)OOCC3C)C1=O+HC4-S4s/31H/@2](#H453((/#H)4#)o()11)/+++3+4(2-15()1(cNC)]O(F)3)C33)C)3OO3COO33)3OC3)3C3)33O)O3333)O)C33O3C)))3C33333)3)O3)3)OO33))))C33))O33OO3O3O3O)O)O)3OO3)O)3)=/#-N)42#(-B2@H/@##2-)-[#-=F(+(H+5(=(++==(FF#H)#5-5-)(((3)]-)]3)OCC3O33)O)))O3O3O333C3))33)C)CO)))CC3)3)CC)33O))3OO)3)33)33O)3OC)3)333O3)CC)3O3)O))O3O33)O3C)33)O3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8zf5HKKOYi3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 : \n",
        "Do a character-level representation for the SMILES molecules.\n"
      ],
      "metadata": {
        "id": "K6zz7iJLUScr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequence = smile_text.from_array[10]\n",
        "print(\"SMILE data : \",test_sequence)\n",
        "to_idx = sequence_to_idx(test_sequence)\n",
        "print(f\"One hot encoding for {to_idx.shape} , {test_sequence} : \\n\",to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpaj4y_2U4R-",
        "outputId": "b377b511-91e8-42fd-b0a7-a6110a439523"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMILE data :  c1ccc(cc1)[C@@H](C(=O)[O-])O\n",
            "One hot encoding for (200, 35) , c1ccc(cc1)[C@@H](C(=O)[O-])O : \n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2 \n",
        "Train a variational autoencoder that jointly learns to encode SMILES molecules to a latent distribution and reconstructs from the latent distribution."
      ],
      "metadata": {
        "id": "5UFg1RrMUffd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = iter(trainloader).next()[0]\n",
        "test = flatten(torch.tensor( sequence_to_idx(test), dtype= torch.float32 ))\n",
        "\n",
        "mu_learnt = None\n",
        "std_learnt = None\n",
        "loss_array = []\n",
        "bce_loss_array = []\n",
        "kld_loss_array = []\n",
        "for epoch in range(1):\n",
        "    for idx, image in enumerate(trainloader):\n",
        "        # images = [print(sequence_to_idx( a ).shape) for a in image ]\n",
        "        images = flatten(torch.tensor([sequence_to_idx( a ) for a in image ], dtype= torch.float32).reshape(-1,1,1,35))\n",
        "\n",
        "        recon_images, mu, logvar = model(images)\n",
        "        mu_learnt = mu\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        std_learnt = std\n",
        "        \n",
        "        loss, bce_loss, kld_loss = loss_fn(recon_images, images, mu, logvar)\n",
        "        loss_array.append(loss)\n",
        "        bce_loss_array.append(bce_loss)\n",
        "        kld_loss_array.append(kld_loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if idx%100 == 0:\n",
        "            print(\"Epoch[{}/{}] Loss: {:.3f}\".format(epoch+1, 2, loss.item()/32))\n",
        "    \n",
        "            # recon_x, _, _ = model(test)\n",
        "            # save_image(recon_x.view(1, 1, 200, 35).data.cpu(), f'/content/reconstructed/recon_image_{epoch}_{idx}.png')"
      ],
      "metadata": {
        "id": "WftVJtk_duPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3 \n",
        "Sample a latent vector from the standard normal distribution and use the trained VAE modelsâ€™ decoder to reconstruct the SMILES molecules from the latent vectors"
      ],
      "metadata": {
        "id": "31XGV2-BUlok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate( model, mu_learnt, std_learnt )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "z0JNOby8dvnz",
        "outputId": "2c2e96e6-4a54-4615-d8d8-04fe3c2507c0"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c12[C-+#3//-\\\\-HC+3)43/H-B#+#(-++(()315c))1O#N=35)2-c(=]3-C))-O3)4C333O3C)333)3C3))CO3)3O)3C)O)3))))333)O3O)O)O333O)O33333)333)33)3OO)O3CO333))3)C33)33O))O33C3C(Nn+[\\\\/#+122B=2#4-N+=513)))\\\\1-4-1+#@B#/)2@((C))#[)-(5#)=C--O(3)O)O3333CCO)33)C))33O))3O3)3)333)3333O3))3)3C3333O3C3333))333)3)33)3))C3CC3)3))))3)333333CO)O3)CC)O3))CHO2)-1C+2-4-(4+51r/)(1B)2BHFF22I)3((I32+1))/(4#=4C@+C()(#)FOFCC3O)OO))3))333O)3)O-3OO3O)3333OO3)O)333)33333333))3COC3OCO3O3)3)O3))33333)3COO))O)))3OC3333C))OO)33O33)3[[N=+Ps(1)/2/1#(1=/+O/-I#5O)/+-//3O2O+5C/#C/)1C[2)55)(OO)CO3C)3)3O33)3333))3))333O33333)O)O)C)O333O3O3COO3C33O33333)33)3O33O)3O)33O3)33CO33)C33C3C333333))3OOCC)c1H#114=B/+@#45=/FC3(#/+4=F##/=5(O#)()2(=--C2((1-)#4+F#[4CC3))O)33)33O33)3OO33CO333))3)3O)33)OC)33)3333)33C))33)3OO3)33)33OO33)))C3)))O)333O3OOOO))3333)C333/(n@B3#31)+(]###O)O=4#B/2]1-CF+#3-O)=//#5342[#)2#)))OO333C)C33O333C3C)33)3)))33C3C)333))))3333C)OO)3)3)OC)O3)C)O)O)O)33)O)))33C))3)3C33))OC)3C)33)3)33)))3OC11-)(##1(2--#S)#+B-+#3H)c454#-23-=#45-#F-3)C/2((25=N#=]---3)O)3333)33O3C33)O33)33333CC)3OO)333)))333))O))3)33)3)OO3C3C33)33OO3COOO)CCO33)3)33)3O)3))333O33))(1-/+(C--C5//(4CSI12B2C6#/+1(3/64)5=4(#5)3#6C-4(5][)C3OOC3))O3333C3O3))C333C3OCO3333C))C333O3O3C333333O3C33+)3C)3)3)))C33)3O3)3O)O3COO)3))3C3O3)))OO33C))))O[/@2C@+H1)3)13=#3H(#(35(1/5//#C1)((4/#/(443]#3OF##5((=NHCCFC3O)C333)))333)333))333))))3333O)3)33))OO3OC)3)C))O)O3OO)3)3)3C33))))C3)33333C)O)CC)3C)))O)333C/C+(42B/CB3(+F1/+46/3C)n+[BC35F@((46+)=4+#+@-4(=l()--)C3C))33)O)33))))33C3)33)333)))3333)3333)CCO)33))C)3))33H3)3O)O33C3)C33))3)33)OO)33O33333)O3C3))O3O3)333C[H-H3/12F()I1]4H+I--3+#o51/+111-23#++((3(43n-)5H@=C4N)-FC3)O)CC3CC)3)OC3)C33O33C333)O3))3))33O3O3CC))3)33)3)33OOO))O)C333)))33C))3)O)3O33C)3))O3)O333))O)))3)3)3c/s(#([/B-(52)+C-3)1(+F@5F)-413(26-)4)2Fon//((C##)4H-35)C]FCO3))O3)))))3)3333O3OO3O))333O3O333C3O)C3O3OC3333)OO3OO)3)333))CC)OC3O333C333C))3O))O3)33)C)3)3CC))3)C(OC)=)##C-#-P(BF(F24)s24#@-6==3##@)+55+4(/)4BcH31@N11n5=()4(C[C)C)O3)OC3333O3O333C3)C3O3)))33O3)3CC3O3C3)33))3OC)CC)3CO))CO33CO33C333O3)C)3O3C))33C))3)333)3C3))[13#3/1#1-2I(#-)-1/#S1P23#1[31/H///1-=52((5/(1+5#-4((4#O)O3)C33)3O3)33)33)33)3333C333)3)33333OC))3O33))3)3)C)))33)333C3333)C33)33)3)))333)333))3O))OC3C)C)O33)3)33cC1o2/(C44O=2(+5125-3+FI6/#O#3@+42(-#B@/B2+5O32C#)3](+(()---]3O)C33CO3C3333)3C3)O)3OO3)3333O)33C)C333O3COO)O33O33)C333O33333OC)))O)333O33CC3O3O)OO33)OC3))C333)33)O3[O//#))F3+H(/+#4#/S)6(+-F1B/[)#([)#/-(52#l15-1+5(3-4)4+5=)[(]OO)C33)O)3))33)C)3333)3C3CC3C))3333)333C)3)3O33O33333O3)3C3C)33O)3)33C33C)C333)333))OO33O3C3O33)C3O3CSON)C2(=()+/#5/S+5N2N+4\\\\-B[+B142/2=4B4((+=1-1C#F[=##+)=5=)C3)))O)O33)))CO333)C)33))OO)O)3OO)3)3CO)))C)C3)33)3OCC333C333O)333)C33))3C))3C))333C)3)3)3)C3)33)C)3)33)OO11/@1OB1113+5#+1@2/B(+B//NN(14)(()-@+H)5)1(-O53C)4FC3)C)C3333)333333))33OC3C3C3C3)3)O3C3)33O3)3)3O33O))3)33))33O33)333O)33)))C))C)3COOC)3333)))3))))CC)3O)(+3)(#B#(23(3-)(=5--3+C+/45#-1[=(@4@B((++255F/2o)5(#==#)O]FO3)O)C)3)33))333C3)O33333C33)C3))3COO3)))3)3)333))O3)33COCC)3COC)3)))O33)3C333OCO33OO3)3OC)3))33C)C3C1N1)+]#-n#+B1)[--3I254-F@(In+4+4/1//)-6C4-(2+#4((#F5=#45(#5-4]O3))CC)3/)3)OC)33)OOO3))33))33)C))3O3333333O)3C)C3O3)3O33C33O))3))C33)O)3333O)O)3))3)333O)3CC33O))OO3)3)3(/C@-)(((3O#()[(OC-4[O5(F\\\\F1C3-(B4#/3/443)(1-B#-]#-13F#)4c)#N(=)))3O)O33)333O)3)))OC3)O3333)3)O3)CC)O333))3OO3))O)3)))F)CO)C)333)3)33C3)333)))3)33)3)3C3)3O33C))3O3OC3C3C33)3C333C11=1))(3@(#4-=4=5--/2++(Ns-/-B1#52[16#=#1On435-52[(5(+O)#[-)O)O)333)3C)3O)333))333OCC)3)33333C33OO3COC3)3))3333OOO)3)3))OO3333)3C)3333))3O))OCOO33333333C(((+C=([#r3B2+1B/5C#())=133252/C+r@/OnBC(#)2n1C(=#)[)FOO)OC333333O33))3O)33O)O33)C)O333O33CO)O333C)))3OCO3OO)C3)O3O)3O3C3CC)))3OC)CC))3))O3C33)333O)O3)33C1/H/(S1H1/#--)n44(-#(+CF4++C2#/@5H=#@/)#)--22Fn+43N@##O)5()](]OC))))C3O3333)3)3333c)OC333)C3O333)))))3)3)33))33)3C3O)3C33333OO33OO33CO3)333OC3C3C3)))3)33333)3O3CCC/1+S))-(54(2#+1/((431/-/=+314=)-=-B-)H(=#---##1##(##+)#N-3O))))333)))O3)3O3OO33O))3O3O3)33333)))O3O33)))C33)))C))3O)CcC33)33333C3CC3)O)3C3C33CO)3O3)3OCOO)3)3O)33)[///+1#@)-I#255)#1)+(@F=)O2#O1O/15(OrS)#)4#3#3-14)#O)C-)3)CCOO3))333)C33CO3)C)33O)O)33C3)3O))))33))333OC33OC)3O)3)3O3O)))3O3)))))3)3O3)O3O3OC3333)CC)3CP@)=#41-#)O)3(C##NF#@])#)-)6((4/4I@-5@l+)-F@C#=)[3CO)))3O)3O3333OCC)3333)3333O33C)3)3)3C3H333OC33)CO3OOCO3))333C)333)33))C3)O)33)))333O3)3)3O3333O))33OC3))))3)33)[#nC=H/+4-/(C2N)#-31(N-2c)5r5-5-4(6[#-(-+@B=+)(N([4+)=NC(]]3O)C)O33)3C)3OCO33O33OO3333)33))C3333)3COO33333))))3))O)C33O3))3)))3)))3)3O3C3OOCC3)3OO))OO)C3)O3)))\\\\CO33C(-/+##+/P=2#)(C-N(2\\\\))5])25(@#S-@1(=1/@(4@/-C+4(()(3N3[(O)O)C3)33)O3O33C))))333C33)C3H3))3OC3)333O3333))OO3OC3C3OOOC3333333O))33)OO)))3)33)3O3)))CC3)3C3333)CN1C31/#-O#(3S(2/S=SO+3/C3))#(+63@r+2)-(+r25##2#+CF(+=NON#([F-F--)O)CO33O)O)333)C33)))33333)))3CO)333C333[33333O)CO3C3)))333O33)O=3)C)333O)O3)))33)333)3C))3333COOc\\\\@--)N1#-)\\\\O#[S(O3-2+#H-#31/)#5=]((2/-/+C-/(15F4(#+)(3-OC3)COC3)O3)33)3)O3333))3O33)O)3))3)333O)C)3C3))3O33333)3O)3)333)3)C333CO33)C)33O)333O33)33C3C3)33C33O3)C3)33//H=S=]4))N=-4++F@)#-5C)4#@/@2(//o+@33r[(4#-#N-3C#))(()O))O))3)33O3)O3)3C33))33)3)3)3))3)3))3O333O))O3O3+)33)3)CCO3))3))3333)3)3))O33))33OC3))3OOO))C))))))3)C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4\n",
        "Implement a simple decoder to decode the generated samples and parse them to character representation."
      ],
      "metadata": {
        "id": "ZFwa6BRsUtMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_char = idx_to_sequence(to_idx)\n",
        "print(f\"To SMILE data : \", to_char )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bpfzgYLd9zt",
        "outputId": "c89cf301-7350-45f2-c463-b826cfe42a39"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To SMILE data :  C[c#(/1=CHNOS[cn#(/1=CNOPS[\\]cn(+/12=@CHNOPS[\\cnos()+-/12=@CHNOPS[\\]cnos#()+-/12=@CHNOPS[\\]cnos#()+-/123=@CFHNOPS[\\]cnos#()+-/123=@CHNOPS[\\]cnos#()+-/1234=@CHNOPS[\\]clnos#()+-/1234=@BCFHNOS[\\]clnos#()+-/1234=@BCFHINOPS[\\]clnors#()+-/1234=@BCFHINOPS[\\]clnors#()+-/1234=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOPS[\\]clnors#()+-/1234=@BCFHINOPS[\\]clnors#()+-/1234=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOPS[\\]clnors#()+-/1234=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/12345=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/123456=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/123456=@BCFHINOPS[\\]clnors#()+-/12345=@BCFHINOPS[\\]clnors#()+-/123456=@BCFHINOS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/123456=@BCFHNOS[\\]clnors#()+-/123456=@BCFHINOS[\\]clnors#()+-/123456=@BCFHINOS[\\]clnors#()+-/12345=@BCFHNOS[\\]clnors#()+-/12345=@BCFHNOS[\\]clnors#()+-/12345=@BCFHNOS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/123456=@BCFHINOS[\\]clnors#()+-/12345=@BCFHINOS[\\]clnors#()+-/123456=@BCFHNOS[\\]clnors#()+-/123456=@BCFHNOS[\\]clnors#()+-/12345=@BCFHNOS[\\]clnors#()+-/123456=@BCFHNOS[\\]clnors#()+-/12345=@BCFHNOS[]clnors#()+-/12345=@BCFHNOS[\\]clnors#()+-/12345=@BCFHNOS[\\]clnors#()+-/12345=@BCFHNO[\\]clnors#()+-/12345=@CFHNO[]clnors#()+-12345=@CFHNOS[]clnos#()+-/12345=@CFHNOS[]clnos#()+-12345=@BCFHNOS[]clno#()+-12345=@CFHNO[]clnor#()+-/12345=@BCFHNO[]cln#()-12345=@CFHNO[]clnrs#()-123456=CFHNO[]clno#()+-12345=@CFNO[]cln#()+-12345=@BCFHNO[]c#()-345=CNO[]cr#()+-1345=CFNO[]c#()+-345=@CFNO[]c#()+3456=CFNO]cl#()+45=CNO]cl#()35=CNO[]()345=CFNOl#)-5=O[)CFNO[])-4CHO[(+-CO[]-=FO])-4CO])CF]CO3)O)C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8iOGUiiMuGU9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}